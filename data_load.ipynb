{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7894671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始数据集划分\n",
      "*********************************C1class1*************************************\n",
      "C1class1类按照0.8：0.2：0.0的比例划分完成，一共4000张图片\n",
      "训练集Z:\\Jupyter_work\\tensorflow\\Eight\\data_24_TL_CNN\\train\\C1class1：3201张\n",
      "验证集Z:\\Jupyter_work\\tensorflow\\Eight\\data_24_TL_CNN\\val\\C1class1：799张\n",
      "测试集Z:\\Jupyter_work\\tensorflow\\Eight\\data_24_TL_CNN\\test\\C1class1：0张\n",
      "*********************************C1class2*************************************\n",
      "C1class2类按照0.8：0.2：0.0的比例划分完成，一共4000张图片\n",
      "训练集Z:\\Jupyter_work\\tensorflow\\Eight\\data_24_TL_CNN\\train\\C1class2：3201张\n",
      "验证集Z:\\Jupyter_work\\tensorflow\\Eight\\data_24_TL_CNN\\val\\C1class2：799张\n",
      "测试集Z:\\Jupyter_work\\tensorflow\\Eight\\data_24_TL_CNN\\test\\C1class2：0张\n",
      "*********************************C1class3*************************************\n",
      "C1class3类按照0.8：0.2：0.0的比例划分完成，一共4000张图片\n",
      "训练集Z:\\Jupyter_work\\tensorflow\\Eight\\data_24_TL_CNN\\train\\C1class3：3201张\n",
      "验证集Z:\\Jupyter_work\\tensorflow\\Eight\\data_24_TL_CNN\\val\\C1class3：799张\n",
      "测试集Z:\\Jupyter_work\\tensorflow\\Eight\\data_24_TL_CNN\\test\\C1class3：0张\n",
      "*********************************C1class4*************************************\n",
      "C1class4类按照0.8：0.2：0.0的比例划分完成，一共4000张图片\n",
      "训练集Z:\\Jupyter_work\\tensorflow\\Eight\\data_24_TL_CNN\\train\\C1class4：3201张\n",
      "验证集Z:\\Jupyter_work\\tensorflow\\Eight\\data_24_TL_CNN\\val\\C1class4：799张\n",
      "测试集Z:\\Jupyter_work\\tensorflow\\Eight\\data_24_TL_CNN\\test\\C1class4：0张\n",
      "*********************************C2class1*************************************\n",
      "C2class1类按照0.8：0.2：0.0的比例划分完成，一共4000张图片\n",
      "训练集Z:\\Jupyter_work\\tensorflow\\Eight\\data_24_TL_CNN\\train\\C2class1：3201张\n",
      "验证集Z:\\Jupyter_work\\tensorflow\\Eight\\data_24_TL_CNN\\val\\C2class1：799张\n",
      "测试集Z:\\Jupyter_work\\tensorflow\\Eight\\data_24_TL_CNN\\test\\C2class1：0张\n",
      "*********************************C2class2*************************************\n",
      "C2class2类按照0.8：0.2：0.0的比例划分完成，一共4000张图片\n",
      "训练集Z:\\Jupyter_work\\tensorflow\\Eight\\data_24_TL_CNN\\train\\C2class2：3201张\n",
      "验证集Z:\\Jupyter_work\\tensorflow\\Eight\\data_24_TL_CNN\\val\\C2class2：799张\n",
      "测试集Z:\\Jupyter_work\\tensorflow\\Eight\\data_24_TL_CNN\\test\\C2class2：0张\n",
      "*********************************C2class3*************************************\n",
      "C2class3类按照0.8：0.2：0.0的比例划分完成，一共4000张图片\n",
      "训练集Z:\\Jupyter_work\\tensorflow\\Eight\\data_24_TL_CNN\\train\\C2class3：3201张\n",
      "验证集Z:\\Jupyter_work\\tensorflow\\Eight\\data_24_TL_CNN\\val\\C2class3：799张\n",
      "测试集Z:\\Jupyter_work\\tensorflow\\Eight\\data_24_TL_CNN\\test\\C2class3：0张\n",
      "*********************************C2class4*************************************\n",
      "C2class4类按照0.8：0.2：0.0的比例划分完成，一共4000张图片\n",
      "训练集Z:\\Jupyter_work\\tensorflow\\Eight\\data_24_TL_CNN\\train\\C2class4：3201张\n",
      "验证集Z:\\Jupyter_work\\tensorflow\\Eight\\data_24_TL_CNN\\val\\C2class4：799张\n",
      "测试集Z:\\Jupyter_work\\tensorflow\\Eight\\data_24_TL_CNN\\test\\C2class4：0张\n",
      "*********************************C3class1*************************************\n",
      "C3class1类按照0.8：0.2：0.0的比例划分完成，一共4000张图片\n",
      "训练集Z:\\Jupyter_work\\tensorflow\\Eight\\data_24_TL_CNN\\train\\C3class1：3201张\n",
      "验证集Z:\\Jupyter_work\\tensorflow\\Eight\\data_24_TL_CNN\\val\\C3class1：799张\n",
      "测试集Z:\\Jupyter_work\\tensorflow\\Eight\\data_24_TL_CNN\\test\\C3class1：0张\n",
      "*********************************C3class2*************************************\n",
      "C3class2类按照0.8：0.2：0.0的比例划分完成，一共4000张图片\n",
      "训练集Z:\\Jupyter_work\\tensorflow\\Eight\\data_24_TL_CNN\\train\\C3class2：3201张\n",
      "验证集Z:\\Jupyter_work\\tensorflow\\Eight\\data_24_TL_CNN\\val\\C3class2：799张\n",
      "测试集Z:\\Jupyter_work\\tensorflow\\Eight\\data_24_TL_CNN\\test\\C3class2：0张\n",
      "*********************************C3class3*************************************\n",
      "C3class3类按照0.8：0.2：0.0的比例划分完成，一共4000张图片\n",
      "训练集Z:\\Jupyter_work\\tensorflow\\Eight\\data_24_TL_CNN\\train\\C3class3：3201张\n",
      "验证集Z:\\Jupyter_work\\tensorflow\\Eight\\data_24_TL_CNN\\val\\C3class3：799张\n",
      "测试集Z:\\Jupyter_work\\tensorflow\\Eight\\data_24_TL_CNN\\test\\C3class3：0张\n",
      "*********************************C3class4*************************************\n",
      "C3class4类按照0.8：0.2：0.0的比例划分完成，一共4000张图片\n",
      "训练集Z:\\Jupyter_work\\tensorflow\\Eight\\data_24_TL_CNN\\train\\C3class4：3201张\n",
      "验证集Z:\\Jupyter_work\\tensorflow\\Eight\\data_24_TL_CNN\\val\\C3class4：799张\n",
      "测试集Z:\\Jupyter_work\\tensorflow\\Eight\\data_24_TL_CNN\\test\\C3class4：0张\n",
      "*********************************D1class1*************************************\n",
      "D1class1类按照0.8：0.2：0.0的比例划分完成，一共4000张图片\n",
      "训练集Z:\\Jupyter_work\\tensorflow\\Eight\\data_24_TL_CNN\\train\\D1class1：3201张\n",
      "验证集Z:\\Jupyter_work\\tensorflow\\Eight\\data_24_TL_CNN\\val\\D1class1：799张\n",
      "测试集Z:\\Jupyter_work\\tensorflow\\Eight\\data_24_TL_CNN\\test\\D1class1：0张\n",
      "*********************************D1class2*************************************\n",
      "D1class2类按照0.8：0.2：0.0的比例划分完成，一共4000张图片\n",
      "训练集Z:\\Jupyter_work\\tensorflow\\Eight\\data_24_TL_CNN\\train\\D1class2：3201张\n",
      "验证集Z:\\Jupyter_work\\tensorflow\\Eight\\data_24_TL_CNN\\val\\D1class2：799张\n",
      "测试集Z:\\Jupyter_work\\tensorflow\\Eight\\data_24_TL_CNN\\test\\D1class2：0张\n",
      "*********************************D1class3*************************************\n",
      "D1class3类按照0.8：0.2：0.0的比例划分完成，一共4000张图片\n",
      "训练集Z:\\Jupyter_work\\tensorflow\\Eight\\data_24_TL_CNN\\train\\D1class3：3201张\n",
      "验证集Z:\\Jupyter_work\\tensorflow\\Eight\\data_24_TL_CNN\\val\\D1class3：799张\n",
      "测试集Z:\\Jupyter_work\\tensorflow\\Eight\\data_24_TL_CNN\\test\\D1class3：0张\n",
      "*********************************D1class4*************************************\n",
      "D1class4类按照0.8：0.2：0.0的比例划分完成，一共4000张图片\n",
      "训练集Z:\\Jupyter_work\\tensorflow\\Eight\\data_24_TL_CNN\\train\\D1class4：3201张\n",
      "验证集Z:\\Jupyter_work\\tensorflow\\Eight\\data_24_TL_CNN\\val\\D1class4：799张\n",
      "测试集Z:\\Jupyter_work\\tensorflow\\Eight\\data_24_TL_CNN\\test\\D1class4：0张\n",
      "*********************************D2class1*************************************\n",
      "D2class1类按照0.8：0.2：0.0的比例划分完成，一共4000张图片\n",
      "训练集Z:\\Jupyter_work\\tensorflow\\Eight\\data_24_TL_CNN\\train\\D2class1：3201张\n",
      "验证集Z:\\Jupyter_work\\tensorflow\\Eight\\data_24_TL_CNN\\val\\D2class1：799张\n",
      "测试集Z:\\Jupyter_work\\tensorflow\\Eight\\data_24_TL_CNN\\test\\D2class1：0张\n",
      "*********************************D2class2*************************************\n",
      "D2class2类按照0.8：0.2：0.0的比例划分完成，一共4000张图片\n",
      "训练集Z:\\Jupyter_work\\tensorflow\\Eight\\data_24_TL_CNN\\train\\D2class2：3201张\n",
      "验证集Z:\\Jupyter_work\\tensorflow\\Eight\\data_24_TL_CNN\\val\\D2class2：799张\n",
      "测试集Z:\\Jupyter_work\\tensorflow\\Eight\\data_24_TL_CNN\\test\\D2class2：0张\n",
      "*********************************D2class3*************************************\n",
      "D2class3类按照0.8：0.2：0.0的比例划分完成，一共4000张图片\n",
      "训练集Z:\\Jupyter_work\\tensorflow\\Eight\\data_24_TL_CNN\\train\\D2class3：3201张\n",
      "验证集Z:\\Jupyter_work\\tensorflow\\Eight\\data_24_TL_CNN\\val\\D2class3：799张\n",
      "测试集Z:\\Jupyter_work\\tensorflow\\Eight\\data_24_TL_CNN\\test\\D2class3：0张\n",
      "*********************************D2class4*************************************\n",
      "D2class4类按照0.8：0.2：0.0的比例划分完成，一共4000张图片\n",
      "训练集Z:\\Jupyter_work\\tensorflow\\Eight\\data_24_TL_CNN\\train\\D2class4：3201张\n",
      "验证集Z:\\Jupyter_work\\tensorflow\\Eight\\data_24_TL_CNN\\val\\D2class4：799张\n",
      "测试集Z:\\Jupyter_work\\tensorflow\\Eight\\data_24_TL_CNN\\test\\D2class4：0张\n",
      "*********************************D3class1*************************************\n",
      "D3class1类按照0.8：0.2：0.0的比例划分完成，一共4000张图片\n",
      "训练集Z:\\Jupyter_work\\tensorflow\\Eight\\data_24_TL_CNN\\train\\D3class1：3201张\n",
      "验证集Z:\\Jupyter_work\\tensorflow\\Eight\\data_24_TL_CNN\\val\\D3class1：799张\n",
      "测试集Z:\\Jupyter_work\\tensorflow\\Eight\\data_24_TL_CNN\\test\\D3class1：0张\n",
      "*********************************D3class2*************************************\n",
      "D3class2类按照0.8：0.2：0.0的比例划分完成，一共4000张图片\n",
      "训练集Z:\\Jupyter_work\\tensorflow\\Eight\\data_24_TL_CNN\\train\\D3class2：3201张\n",
      "验证集Z:\\Jupyter_work\\tensorflow\\Eight\\data_24_TL_CNN\\val\\D3class2：799张\n",
      "测试集Z:\\Jupyter_work\\tensorflow\\Eight\\data_24_TL_CNN\\test\\D3class2：0张\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_33112\\1375456237.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[0msrc_data_folder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Z:\\\\Jupyter_work\\\\tensorflow\\\\Eight\\\\data_24_TL\"\u001b[0m   \u001b[1;31m# todo 修改你的原始数据集路径\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[0mtarget_data_folder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Z:\\\\Jupyter_work\\\\tensorflow\\\\Eight\\\\data_24_TL_CNN\"\u001b[0m  \u001b[1;31m# todo 修改为你要存放的路径\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m     \u001b[0mdata_set_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc_data_folder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_data_folder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_33112\\1375456237.py\u001b[0m in \u001b[0;36mdata_set_split\u001b[1;34m(src_data_folder, target_data_folder, train_scale, val_scale, test_scale)\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[0msrc_img_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_class_data_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_all_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcurrent_idx\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mtrain_stop_flag\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m                 \u001b[0mcopy2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc_img_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_folder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m                 \u001b[1;31m# print(\"{}复制到了{}\".format(src_img_path, train_folder))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m                 \u001b[0mtrain_num\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_num\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mX:\\Anaconda\\envs\\tensorflow\\lib\\shutil.py\u001b[0m in \u001b[0;36mcopy2\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    264\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m         \u001b[0mdst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 266\u001b[1;33m     \u001b[0mcopyfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    267\u001b[0m     \u001b[0mcopystat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mX:\\Anaconda\\envs\\tensorflow\\lib\\shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msymlink\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlink\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m                 \u001b[0mcopyfileobj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfsrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfdst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from shutil import copy2\n",
    "\n",
    "\n",
    "def data_set_split(src_data_folder, target_data_folder, train_scale=0.8, val_scale=0.2, test_scale=0.0):\n",
    "    '''\n",
    "    读取源数据文件夹，生成划分好的文件夹，分为trian、val、test三个文件夹进行\n",
    "    :param src_data_folder: 源文件夹 E:/biye/gogogo/note_book/torch_note/data/utils_test/data_split/src_data\n",
    "    :param target_data_folder: 目标文件夹 E:/biye/gogogo/note_book/torch_note/data/utils_test/data_split/target_data\n",
    "    :param train_scale: 训练集比例\n",
    "    :param val_scale: 验证集比例\n",
    "    :param test_scale: 测试集比例\n",
    "    :return:\n",
    "    '''\n",
    "    print(\"开始数据集划分\")\n",
    "    class_names = os.listdir(src_data_folder)\n",
    "    # 在目标目录下创建文件夹\n",
    "    split_names = ['train', 'val', 'test']\n",
    "    for split_name in split_names:\n",
    "        split_path = os.path.join(target_data_folder, split_name)\n",
    "        if os.path.isdir(split_path):\n",
    "            pass\n",
    "        else:\n",
    "            os.mkdir(split_path)\n",
    "        # 然后在split_path的目录下创建类别文件夹\n",
    "        for class_name in class_names:\n",
    "            class_split_path = os.path.join(split_path, class_name)\n",
    "            if os.path.isdir(class_split_path):\n",
    "                pass\n",
    "            else:\n",
    "                os.mkdir(class_split_path)\n",
    "\n",
    "    # 按照比例划分数据集，并进行数据图片的复制\n",
    "    # 首先进行分类遍历\n",
    "    for class_name in class_names:\n",
    "        current_class_data_path = os.path.join(src_data_folder, class_name)\n",
    "        current_all_data = os.listdir(current_class_data_path)\n",
    "        current_data_length = len(current_all_data)\n",
    "        current_data_index_list = list(range(current_data_length))\n",
    "        random.shuffle(current_data_index_list)\n",
    "\n",
    "        train_folder = os.path.join(os.path.join(target_data_folder, 'train'), class_name)\n",
    "        val_folder = os.path.join(os.path.join(target_data_folder, 'val'), class_name)\n",
    "        test_folder = os.path.join(os.path.join(target_data_folder, 'test'), class_name)\n",
    "        train_stop_flag = current_data_length * train_scale\n",
    "        val_stop_flag = current_data_length * (train_scale + val_scale)\n",
    "        current_idx = 0\n",
    "        train_num = 0\n",
    "        val_num = 0\n",
    "        test_num = 0\n",
    "        for i in current_data_index_list:\n",
    "            src_img_path = os.path.join(current_class_data_path, current_all_data[i])\n",
    "            if current_idx <= train_stop_flag:\n",
    "                copy2(src_img_path, train_folder)\n",
    "                # print(\"{}复制到了{}\".format(src_img_path, train_folder))\n",
    "                train_num = train_num + 1\n",
    "            elif (current_idx > train_stop_flag) and (current_idx <= val_stop_flag):\n",
    "                copy2(src_img_path, val_folder)\n",
    "                # print(\"{}复制到了{}\".format(src_img_path, val_folder))\n",
    "                val_num = val_num + 1\n",
    "            else:\n",
    "                copy2(src_img_path, test_folder)\n",
    "                # print(\"{}复制到了{}\".format(src_img_path, test_folder))\n",
    "                test_num = test_num + 1\n",
    "\n",
    "            current_idx = current_idx + 1\n",
    "\n",
    "        print(\"*********************************{}*************************************\".format(class_name))\n",
    "        print(\n",
    "            \"{}类按照{}：{}：{}的比例划分完成，一共{}张图片\".format(class_name, train_scale, val_scale, test_scale, current_data_length))\n",
    "        print(\"训练集{}：{}张\".format(train_folder, train_num))\n",
    "        print(\"验证集{}：{}张\".format(val_folder, val_num))\n",
    "        print(\"测试集{}：{}张\".format(test_folder, test_num))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    src_data_folder = \"Z:\\\\Jupyter_work\\\\tensorflow\\\\Eight\\\\data_24_TL\"   # todo 修改你的原始数据集路径\n",
    "    target_data_folder = \"Z:\\\\Jupyter_work\\\\tensorflow\\\\Eight\\\\data_24_TL_CNN\"  # todo 修改为你要存放的路径\n",
    "    data_set_split(src_data_folder, target_data_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e63b59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
