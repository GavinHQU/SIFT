{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f13b8cba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelname SIFT-net3-FC128-0.1-0.005_0.9\n",
      "data 9C1\n",
      "number of class1 76\n",
      "class1 [8, 9, 24, 45, 55, 69, 72]\n",
      "number of class2:0\n",
      "class2:[]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D,MaxPool2D,Activation,Dropout,Flatten,Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import numpy as np\n",
    "np.set_printoptions(linewidth=1000) \n",
    "# model\n",
    "modelsave_name = 'SIFT-net3-FC128-0.1-0.005_0.9'\n",
    "need_GM = 7\n",
    "storey = '9'\n",
    "groud = 'C'\n",
    "group = '1'\n",
    "ARD=[]\n",
    "picsize =256\n",
    "print('modelname',modelsave_name)\n",
    "print('data',storey+groud+group)\n",
    "IMG_SHAPE=(picsize, picsize, 3)    \n",
    "class_num = 4\n",
    "\n",
    "model = tf.keras.models.load_model(\"modelsave\\\\\"+modelsave_name+'.h5')\n",
    "class_names = ['class1','class2','class3','class4']\n",
    "\n",
    "# RDTD\n",
    "path = \"data\\\\F\"+storey+groud+group+\"\\\\\" # RDTD\n",
    "\n",
    "for path,dirs,files in os.walk(path):\n",
    "    files_list = files\n",
    "\n",
    "# print(files_list)\n",
    "files_name_list1=[]\n",
    "files_name_list2=[]\n",
    "result_list1=[]\n",
    "result_list2=[]\n",
    "probabilities_list1=[]\n",
    "probabilities_list2=[]\n",
    "flag_list1 = []\n",
    "flag_list2 = []\n",
    "flag = 0\n",
    "for files_name in files_list:\n",
    "    file_name = path+files_name\n",
    "    img_init = cv2.imread(file_name)\n",
    "    img_init = cv2.resize(img_init, (picsize, picsize))\n",
    "    img = np.asarray(img_init) \n",
    "    outputs = model(img.reshape(1,picsize, picsize, 3))  \n",
    "    result_index = int(np.argmax(outputs))\n",
    "    result = class_names[result_index]  \n",
    "    probabilities = np.max(outputs.numpy()) \n",
    "    flag=flag+1\n",
    "    if  result == class_names[0]:\n",
    "        files_name_list1.append(files_name) \n",
    "        result_list1.append(result) \n",
    "        probabilities_list1.append(probabilities) \n",
    "        flag_list1.append(flag)\n",
    "    elif result == class_names[1]:\n",
    "        files_name_list2.append(files_name) \n",
    "        result_list2.append(result) \n",
    "        probabilities_list2.append(probabilities) \n",
    "        flag_list2.append(flag)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "# Take the first 7 waves with the highest probability\n",
    "\n",
    "if len(result_list1)<need_GM:\n",
    "    class1_max =[]\n",
    "    class1_max_index =[]\n",
    "    class1_datas = list(probabilities_list1)\n",
    "    for i in range(len(result_list1)):\n",
    "        index = class1_datas.index(max(class1_datas))\n",
    "        class1_max.append(max(class1_datas))\n",
    "        class1_datas[index]=0\n",
    "        class1_max_index.append(flag_list1[index])\n",
    "\n",
    "    print('number of class1',len(files_name_list1))\n",
    "    print('class1',class1_max_index)\n",
    "    # print('class1波概率',class1_max)\n",
    "    # 取class2\n",
    "    class2_max =[]\n",
    "    class2_max_index =[]\n",
    "    class2_datas = list(probabilities_list2)\n",
    "    for i in range(need_GM-len(result_list1)):\n",
    "        index = class2_datas.index(max(class2_datas))\n",
    "        class2_max.append(max(class2_datas))\n",
    "        class2_datas[index]=0\n",
    "        class2_max_index.append(flag_list2[index])\n",
    "        for i in class2_max_index:\n",
    "            sum_drift += drift_datas[i-1]\n",
    "    print('number of class2',need_GM-len(result_list1))\n",
    "    print('class2',class2_max_index)\n",
    "else:\n",
    "    class1_max =[]\n",
    "    class1_max_index =[]\n",
    "    class1_datas = list(probabilities_list1)\n",
    "    for i in range(need_GM):\n",
    "        index = class1_datas.index(max(class1_datas))\n",
    "        class1_max.append(max(class1_datas))\n",
    "        class1_datas[index]=0\n",
    "        class1_max_index.append(flag_list1[index])\n",
    "\n",
    "    print('number of class1',len(files_name_list1))\n",
    "    print('class1',class1_max_index)\n",
    "\n",
    "    print('number of class2:0')\n",
    "    print('class2:[]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604f2d11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
